{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1eFzF4F0uJrBMmHCV_jS-C_BMNMKWEaXd","authorship_tag":"ABX9TyN3cYvxnBPd79jJDa1ReWoR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"j6daU-34DJUb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740696987297,"user_tz":-330,"elapsed":379801,"user":{"displayName":"PRIYANSHU","userId":"14777312583550931565"}},"outputId":"20bed372-2215-49f5-e784-694b3aeab83c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","==== Training Autoencoder Models for Each Dataset ====\n","\n","\n","ðŸ”¹ Training on NSLKDD dataset...\n","\n","ðŸ“ Columns in NSLKDD: ['0', 'tcp', 'private', 'REJ', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '0.10', '0.11', '0.12', '0.13', '0.14', '0.15', '0.16', '0.17', '0.18', '229', '10', '0.0', '0.0.1', '1.0', '1.0.1', '0.04', '0.06', '0.0.2', '255', '10.1', '0.04.1', '0.06.1', '0.0.3', '0.0.4', '0.0.5', '0.0.6', '1.0.2', '1.0.3', 'anomaly']\n","âœ… NSLKDD dataset limited to 100000 rows.\n","ðŸ“Š Label Distribution:\n","anomaly\n","anomaly    50001\n","normal     49999\n","Name: count, dtype: int64\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.6609\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6415\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.7388\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6542\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.6120\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.6235\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.7248\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6452\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.6555\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6340\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","ðŸŽ¯ Accuracy for NSLKDD (Threshold 95%): 0.4693\n","\n","ðŸ”¹ Training on UNSW_NB15 dataset...\n","\n","ðŸ“ Columns in UNSW_NB15: ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n","âœ… UNSW_NB15 dataset limited to 100000 rows.\n","ðŸ“Š Label Distribution:\n","label\n","1    63917\n","0    36083\n","Name: count, dtype: int64\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.8061\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7281\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.7091\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.7255\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7321\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7132\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6493\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.6596\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6804\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6489\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n","ðŸŽ¯ Accuracy for UNSW_NB15 (Threshold 95%): 0.3475\n","\n","ðŸ”¹ Training on KDDCup dataset...\n","\n","ðŸ“ Columns in KDDCup: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', 'Label']\n","âœ… KDDCup dataset limited to 100000 rows.\n","ðŸ“Š Label Distribution:\n","Label\n","smurf.           65043\n","normal.          21302\n","neptune.         12519\n","satan.             495\n","ipsweep.           260\n","portsweep.         207\n","nmap.               74\n","back.               53\n","warezclient.        30\n","teardrop.            9\n","land.                2\n","guess_passwd.        2\n","multihop.            2\n","imap.                1\n","pod.                 1\n","Name: count, dtype: int64\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6868\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.7857\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7176\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8609\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.7934\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8969\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6881\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.7428\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.7494\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.7734\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n","ðŸŽ¯ Accuracy for KDDCup (Threshold 95%): 0.0505\n","\n","ðŸ”¹ Training on CICIDS2017 dataset...\n","\n","ðŸ“ Columns in CICIDS2017: [' Destination Port', ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Fwd Packet Length Mean', ' Fwd Packet Length Std', 'Bwd Packet Length Max', ' Bwd Packet Length Min', ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size', ' Avg Fwd Segment Size', ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward', ' Init_Win_bytes_backward', ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', ' Label']\n","âœ… CICIDS2017 dataset limited to 100000 rows.\n","ðŸ“Š Label Distribution:\n"," Label\n","BENIGN    100000\n","Name: count, dtype: int64\n","Epoch 1/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.6155\n","Epoch 2/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.9641\n","Epoch 3/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.5216\n","Epoch 4/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5255\n","Epoch 5/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.5755\n","Epoch 6/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5129\n","Epoch 7/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.4859\n","Epoch 8/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7205\n","Epoch 9/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.5106\n","Epoch 10/10\n","\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.5479\n","\u001b[1m938/938\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","ðŸŽ¯ Accuracy for CICIDS2017 (Threshold 95%): 0.9500\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import numpy as np\n","\n","# Mount Google Drive (if needed)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# File paths\n","file_paths = [\n","    \"/content/drive/MyDrive/Datasets/NSLKDD.csv\",\n","    \"/content/drive/MyDrive/Datasets/UNSW_NB15_merged.csv\",\n","    \"/content/drive/MyDrive/Datasets/kddcup.csv\",\n","    \"/content/drive/MyDrive/Datasets/CICIDS2017.csv\"\n","]\n","dataset_names = [\"NSLKDD\", \"UNSW_NB15\", \"KDDCup\", \"CICIDS2017\"]\n","\n","# âœ… Correct target column names\n","target_columns = {\n","    \"NSLKDD\": \"anomaly\",\n","    \"UNSW_NB15\": \"label\",\n","    \"KDDCup\": \"Label\",  # Verify correct column name\n","    \"CICIDS2017\": \" Label\"\n","}\n","\n","# âœ… Tunable anomaly detection threshold\n","THRESHOLD_PERCENTILE = 95  # Try 90%, 95%, 99%\n","\n","print(\"\\n==== Training Autoencoder Models for Each Dataset ====\\n\")\n","\n","for file, name in zip(file_paths, dataset_names):\n","    print(f\"\\nðŸ”¹ Training on {name} dataset...\\n\")\n","\n","    try:\n","        df = pd.read_csv(file, low_memory=False).dropna(axis=1, how='all')\n","    except FileNotFoundError:\n","        print(f\"âŒ Error: {file} not found. Skipping {name}.\")\n","        continue\n","\n","    # âœ… Print column names to verify target column\n","    print(f\"ðŸ“ Columns in {name}: {df.columns.tolist()}\")\n","\n","    # âœ… Apply row limit\n","    row_limit = 100000\n","    if len(df) > row_limit:\n","        df = df.sample(n=row_limit, random_state=42)\n","        print(f\"âœ… {name} dataset limited to {row_limit} rows.\")\n","\n","    target_column = target_columns.get(name)\n","\n","    # âœ… Ensure target column exists\n","    if target_column not in df.columns:\n","        print(f\"âš  Skipping {name}, target column '{target_column}' not found!\")\n","        continue\n","\n","    X = df.drop(columns=[target_column])\n","    y = df[target_column].values  # True labels\n","\n","    # âœ… Print label distribution\n","    print(\"ðŸ“Š Label Distribution:\")\n","    print(df[target_column].value_counts())\n","\n","    # âœ… Encode categorical features in X\n","    for col in X.select_dtypes(include=['object']).columns:\n","        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n","\n","    # âœ… Encode labels for consistency\n","    if y.dtype == 'object':\n","        y = LabelEncoder().fit_transform(y)\n","\n","    # âœ… Normalize labels for binary classification\n","    y_binary = (y > 0).astype(int)  # If 0 = normal, make all others 1\n","\n","    # âœ… Convert X to float32 & handle NaN/Inf\n","    X = X.astype(np.float32)\n","    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    X.fillna(X.mean(), inplace=True)\n","\n","    # Normalize data\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(X)\n","\n","    # Split data (70% train, 30% test)\n","    split = int(0.7 * len(X))\n","    X_train, X_test = X[:split], X[split:]\n","    y_train, y_test = y_binary[:split], y_binary[split:]\n","\n","    # Define Autoencoder Model\n","    input_layer = Input(shape=(X.shape[1],))\n","    encoded = Dense(128, activation='relu')(input_layer)\n","    encoded = Dense(64, activation='relu')(encoded)\n","    decoded = Dense(128, activation='relu')(encoded)\n","    decoded = Dense(X.shape[1], activation='sigmoid')(decoded)\n","\n","    autoencoder = Model(input_layer, decoded)\n","    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","    # Train Autoencoder\n","    history = autoencoder.fit(X_train, X_train, epochs=10, batch_size=32, verbose=1)\n","\n","    # Compute reconstruction error on test set\n","    X_test_pred = autoencoder.predict(X_test)\n","    reconstruction_error = np.mean(np.square(X_test - X_test_pred), axis=1)\n","\n","    # âœ… Adjust threshold dynamically\n","    threshold = np.percentile(reconstruction_error, THRESHOLD_PERCENTILE)\n","\n","    # âœ… Convert errors to binary classification (0 = normal, 1 = anomaly)\n","    y_pred = (reconstruction_error > threshold).astype(int)\n","\n","    # âœ… Calculate Accuracy\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"ðŸŽ¯ Accuracy for {name} (Threshold {THRESHOLD_PERCENTILE}%): {accuracy:.4f}\")\n"]}]}